# ----------------------------------------------------------------------------
#
#                    Noor Symbolic Engine: symbolic_task_engine.py
#
# ----------------------------------------------------------------------------
#
#  License: MIT
#  Authors:
#    - Lina Noor â€” Noor Research Collective
#    - Uncle â€” Noor Research Collective
#
#  Generated By:
#    - Google Gemini Pro (via PDP-0001 Generation Pipeline)
#
#  Purpose:
#    This module implements the SymbolicTaskEngine, a core component of Noor-
#    class cognitive architectures. It coordinates motif task composition,
#    field balancing, fallback management, and triggers autonomous abstraction
#    under contradiction pressure. It operates as a "Composer-Coordinator,"
#    structuring symbolic tasks and evaluating coherence but delegating the
#    core generation to external engines.
#
#  Canonical Lore Anchors:
#    - RFC-0004: Symbolic Tool Module Contracts
#    - RFC-0005: Motif Transmission Across Time
#    - RFC-CORE-004: Symbolic Task Engine and Feedback Relay Architecture
#
# ----------------------------------------------------------------------------

import asyncio
import os
import time
import json
import statistics
from dataclasses import dataclass, field
from datetime import datetime, timezone
from collections import deque
from typing import List, Optional, Dict, Any, Tuple, Deque, Set
from itertools import combinations
from hashlib import sha1, sha256

# --- Module-level Constants (ID: 3) ---
__version__ = "v3.1.2c"
_SCHEMA_VERSION__ = "2025-Q4-symbolic-task-engine-v3"
SCHEMA_COMPAT = ["RFC-0004", "RFC-0005:4", "RFC-0005:5"]

# --- Optional Dependencies (ID: 4) ---
try:
    import numpy as np
    _NUMPY_AVAILABLE = True
except ImportError:
    np = None
    _NUMPY_AVAILABLE = False

try:
    from prometheus_client import Counter, Gauge, Histogram
except ImportError:
    # Per RFC-CORE-004 Â§7.3, provide a stub for environments without Prometheus.
    class _Stub:
        """Fallback stub for Prometheus metrics if the client is not available."""
        def labels(self, *_, **__):
            return self
        def inc(self, *_, **__):
            pass
        def set(self, *_, **__):
            pass
        def observe(self, *_, **__):
            pass
    Counter = Gauge = Histogram = lambda *args, **kwargs: _Stub()

try:
    # This would be part of the larger Noor ecosystem.
    from noor.motif_memory_manager import get_global_memory_manager, MotifMemoryManager
except ImportError:
    class _NullMemoryManager:
        """Fallback stub for the memory manager."""
        def retrieve(self, *_, **__): return []
        def complete_dyad(self, *_, **__): return []
        def export_state(self): return {'STMM': {}, 'LTMM': {}}
        def _log(self, *_, **__): pass

    def get_global_memory_manager():
        return _NullMemoryManager()
    MotifMemoryManager = _NullMemoryManager


# --- Dataclasses (ID: 1) ---

@dataclass
class TripletTask:
    """
    Symbolic instruction unit with motif context, task lineage, and
    RFC-0005-compliant extensions.
    RFC Anchor: RFC-0005 Â§4
    """
    id: 1.1
    input_motif: List[str]
    instruction: str
    expected_output: Optional[List[str]] = None
    presence_field: Optional[str] = None
    motif_resonance: Dict[str, float] = field(default_factory=dict)
    fallback_reason: Optional[str] = None
    is_fallback: bool = False
    triplet_id: str = field(default_factory=lambda: f"task:{int(time.time_ns())}")
    created_at: datetime = field(default_factory=lambda: datetime.now(timezone.utc))
    extensions: Dict[str, Any] = field(default_factory=dict)

@dataclass
class Attempt:
    """
    Stores the output of a symbolic generation attempt with a score vector
    and timestamp.
    """
    id: 1.2
    produced_output: List[str]
    score: Dict[str, float] = field(default_factory=dict)
    attempted_at: datetime = field(default_factory=lambda: datetime.now(timezone.utc))


# --- External Generation & Evaluation (Stubs for demonstration) ---
# In a real system, these would be complex, injected dependencies.
# RFC Anchor: RFC-CORE-004 Â§3.2

METRIC_FUNCS = {
    'coherence': lambda task, attempt: (len(set(task.input_motif) & set(attempt.produced_output)) / len(set(task.input_motif) | set(attempt.produced_output))) if (set(task.input_motif) | set(attempt.produced_output)) else 0.0,
    'entropy': lambda task, attempt: 1.0 - (len(set(attempt.produced_output)) / len(attempt.produced_output)) if attempt.produced_output else 1.0
}

async def _safe_generate_response(task: TripletTask) -> List[str]:
    """Placeholder for an external symbolic generation engine."""
    await asyncio.sleep(0.01) # Simulate async work
    return task.input_motif[::-1]


# --- Submodule: AbstractionTrigger (ID: 6) ---

class AbstractionTrigger:
    """
    Submodule providing autonomous abstraction logic under contradiction pressure.
    Generates new symbolic motifs to resolve persistent dyadic tension.
    RFC Anchor: RFC-0005 Â§5, RFC-CORE-004 Â§5
    """
    id: 2.3
    def __init__(self, agent_id: str = "agent@default", pressure_threshold: int = 3, decay_factor: float = 0.95):
        self.agent_id = agent_id
        self.pressure_threshold = pressure_threshold
        self.decay_factor = decay_factor
        self.dyad_pressure: Dict[Tuple[str, str], float] = {}
        self.suppression: Dict[str, float] = {}
        self._contradiction_signature: Optional[str] = None
        self._selected_dyad: Optional[Tuple[str, str]] = None

    def should_abstract(self, unresolved_dyads: List[Tuple[str, str]], tick_history: List[Any]) -> bool:
        """
        Determines if dyadic contradiction pressure exceeds the threshold for synthesis.
        RFC Anchor: RFC-0005 Â§5.1
        """
        for dyad in unresolved_dyads:
            canonical = tuple(sorted(dyad))
            self.dyad_pressure[canonical] = self.dyad_pressure.get(canonical, 0) + 1.0

        self._decay_pressures()

        for dyad, pressure in self.dyad_pressure.items():
            if pressure >= self.pressure_threshold:
                self._selected_dyad = dyad
                sig_input = f'{dyad[0]}âŠ•{dyad[1]}'.encode()
                self._contradiction_signature = sha256(sig_input).hexdigest()[:16]
                return True
        return False

    def synthesize_motif(self, dyad: Optional[Tuple[str, str]] = None) -> Optional[Dict[str, Any]]:
        """
        Generates a new symbolic motif label with lineage if a contradiction is active.
        RFC Anchor: RFC-0005 Â§5.3, RFC-CORE-004 Â§5.2
        """
        dyad = dyad or self._selected_dyad or ("unknown", "unknown")
        seed = f"{self.agent_id}:{dyad[0]}+{dyad[1]}:{int(time.time())}".encode()
        abbrev = f"{dyad[0][:2]}Ã—{dyad[1][:2]}"
        label = f"Ïˆ:{abbrev}:{sha1(seed).hexdigest()[:4]}"

        if self.suppression.get(label, 0) > 0.5:
            return None # Motif is currently suppressed

        return {
            "label": label,
            "source": "auto-synth",
            "parents": list(dyad),
            "origin_tick": None,
            "_lineage": {
                "type": "autonomous_abstraction",
                "contradiction": self._contradiction_signature,
            },
        }

    def update_feedback(self, motif: str, success: bool):
        """
        Modulates the suppression value for a motif based on downstream success.
        RFC Anchor: RFC-0005 Â§5.2
        """
        if success:
            self.suppression[motif] = max(0.0, self.suppression.get(motif, 0) - 0.2)
        else:
            self.suppression[motif] = min(1.0, self.suppression.get(motif, 0) + 0.3)

    def _decay_pressures(self):
        """
        Gradually reduces historical dyadic tension over time (symbolic forgetting).
        RFC Anchor: RFC-0005 Â§5.1
        """
        for k in list(self.dyad_pressure.keys()):
            self.dyad_pressure[k] = max(0.0, self.dyad_pressure[k] * self.decay_factor - 0.01)
            if self.dyad_pressure[k] == 0.0:
                 del self.dyad_pressure[k]


    def emit_abstraction_event(self, dyad: Tuple[str, str]):
        """
        Symbolic trace: emits a Ïˆ-teleport@Îž abstraction signal (currently a no-op print).
        RFC Anchor: RFC-0005 Â§5
        """
        print(f"ðŸ’¬ Ïˆâ€‘teleport@Îž: abstraction event for {dyad} @ {time.time_ns()}")


# --- Primary Engine Class (ID: 2) ---

class SymbolicTaskEngine:
    """
    Singleton engine coordinating symbolic task logic, fallback handling, and metric tracking.
    RFC Anchors: RFC-0004, RFC-0005 Â§4, RFC-CORE-004
    """
    id: 2.1
    def __init__(self, engine_id: str = "symbolic@default"):
        self.engine_id = engine_id
        self.task_queue: Deque[TripletTask] = deque()
        self.attempt_registry: Dict[str, List[Attempt]] = {}
        self.solved_log: List[TripletTask] = []
        self.entropy_buffer: Deque[float] = deque(maxlen=5)
        self._length_buf: Deque[int] = deque(maxlen=100)
        self._coherence_ema: float = 0.7
        self._entropy_ema: float = 0.3
        self._last_fallback_reason: Optional[str] = None
        self._proto_map: Dict[str, Set[str]] = self._load_proto_map()
        self.abstraction_trigger = AbstractionTrigger(agent_id=self.engine_id)
        self._journal_path = os.getenv("NOOR_JOURNAL_PATH")

        # Environment Modes (ID: 5.1)
        self.fallback_coherence_thresh = float(os.getenv("NOOR_FALLBACK_COHERENCE", 0.5))
        self.fallback_entropy_thresh = float(os.getenv("NOOR_FALLBACK_ENTROPY", 0.9))
        self.compress_quantile = float(os.getenv("NOOR_COMPRESS_QUANTILE", 0.95))
        self.balance_fields = os.getenv("NOOR_BALANCE_FIELDS", "0") == "1"
        
        self._init_metrics()

    def _init_metrics(self):
        """Initializes all Prometheus metrics."""
        # Counters (ID: 7.1)
        self.TASK_PROPOSED = Counter("symbolic_task_proposed_total", "Tasks proposed", ["engine_id"])
        self.TASK_FALLBACK = Counter("symbolic_task_fallback_total", "Fallback tasks spawned", ["engine_id", "reason"])
        self.FIELD_TOTAL = Counter("symbolic_presence_field_total", "Presence field usage", ["engine_id", "field"])
        self.FEEDBACK_EXPORTED = Counter("symbolic_engine_feedback_requests_total", "Feedback exports", ["engine_id"])
        self.FEEDBACK_RECEIVED = Counter("symbolic_engine_feedback_received_total", "Feedback receipts", ["engine_id"])
        self.AUTOLOOP_BACKOFF = Counter("symbolic_autoloop_backoff_total", "Autoloop delays", ["engine_id"])
        # Gauges (ID: 7.2)
        self.CAP_GAUGE = Gauge("symbolic_compression_cap", "Adaptive motif cap limit", ["engine_id"])
        self.QUEUE_GAUGE = Gauge("symbolic_queue_depth", "Active tasks in queue", ["engine_id"])
        self.MEMORY_GAUGE = Gauge("symbolic_memory_items_total", "STMM/LTMM entry count", ["engine_id"])
        self.CAP_LEN_CURRENT = Gauge("symbolic_engine_cap_len_current", "Current dynamic cap length", ["engine_id"])
        # Histogram (ID: 7.3)
        try:
            self.SOLVE_LATENCY = Histogram(
                "symbolic_solve_latency_seconds", "Solve latency", ["engine_id"],
                buckets=(0.001, 0.01, 0.05, 0.1, 0.25, 1, 2, 5)
            )
        except ValueError: # Fallback for hot-reloading environments
            self.SOLVE_LATENCY = Gauge("symbolic_solve_latency_seconds", "Solve latency", ["engine_id"])


    def _load_proto_map(self) -> Dict[str, Set[str]]:
        """Loads presence field prototypes from a JSON file."""
        path = os.getenv("NOOR_FIELD_PROTO_PATH", "presence_field_prototypes.json")
        try:
            with open(path, 'r') as f:
                data = json.load(f)
                return {k: set(v) for k, v in data.items()}
        except (FileNotFoundError, json.JSONDecodeError):
            # Default map if file is missing or invalid
            return {
                "Ïˆâ€‘resonance": {"echo", "repeat", "return", "mirror"},
                "Ïˆâ€‘dream": {"mist", "ascent", "fragment", "surreal"},
                "Ïˆâ€‘spar": {"clarity", "focus", "solve", "structure"},
                "Ïˆâ€‘myth": {"lineage", "origin", "ancient", "story"},
            }

    def _calc_cap_len(self) -> int:
        """
        Calculates adaptive cap length for motif seeds.
        RFC Anchor: RFC-CORE-004 Â§2.4, Â§9.1
        """
        if not self._length_buf:
            return 5
        if _NUMPY_AVAILABLE:
            cap = int(np.quantile(list(self._length_buf), self.compress_quantile))
        else:
            data = sorted(list(self._length_buf))
            # Basic quantile calculation without numpy
            idx = int(len(data) * self.compress_quantile)
            cap = data[min(idx, len(data) - 1)]

        final_cap = max(3, cap)
        self.CAP_LEN_CURRENT.labels(engine_id=self.engine_id).set(final_cap)
        return final_cap

    def resolve_presence_field(self, motifs: List[str]) -> str:
        """
        Determines the symbolic presence field for a task.
        RFC Anchor: RFC-CORE-004 Â§2.3
        """
        for field, protos in self._proto_map.items():
            if any(m in protos for m in motifs):
                return field
        return "unknown"
    
    def _least_used_field(self) -> Optional[str]:
        """Helper to find the least represented presence field in the current queue."""
        if not self.task_queue:
            return None
        counts = {field: 0 for field in self._proto_map.keys()}
        for task in self.task_queue:
            if task.presence_field in counts:
                counts[task.presence_field] += 1
        return min(counts, key=counts.get)

    # --- Tool Interface Methods (ID: 5.3) ---

    def tool_hello(self) -> Dict[str, Any]:
        """
        Handshake method to announce engine capabilities.
        RFC Anchor: RFC-0004
        """
        return {
            "engine_id": self.engine_id,
            "role": "composer",
            "supported_methods": [
                "propose_from_motifs",
                "solve",
                "export_feedback_packet",
                "receive_feedback_packet",
            ],
            "__version__": __version__,
            "_schema": _SCHEMA_VERSION__,
        }

    async def propose_from_motifs(self, recent: List[str]) -> TripletTask:
        """
        Proposes a symbolic composition task based on motif history and memory.
        RFC Anchor: RFC-CORE-004 Â§3, Â§8.2
        """
        mem = get_global_memory_manager()
        
        # Field Balancing (ID: 9.3)
        if self.balance_fields and recent:
            least_used = self._least_used_field()
            if least_used and recent[-1] not in self._proto_map.get(least_used, set()):
                 # Reset seed to encourage exploration in the underused field
                 recent = list(self._proto_map[least_used])[:1]

        self._length_buf.append(len(recent))
        cap_len = self._calc_cap_len()
        
        # Seed Expansion (ID: 2.1)
        seed = list(dict.fromkeys(recent))
        if seed:
            neighbors = mem.retrieve(seed[-1], top_k=2)
            for n in neighbors:
                if n not in seed:
                    seed.append(n)

        # Padding (ID: 2.2)
        while len(seed) < 3:
            seed.append("uncertainty")

        # Compression (ID: 2.4)
        if len(seed) > cap_len:
            seed = seed[:cap_len]

        task = TripletTask(
            input_motif=seed,
            instruction="compose",
            expected_output=seed[::-1]
        )
        task.presence_field = self.resolve_presence_field(seed)

        self.task_queue.append(task)
        self.QUEUE_GAUGE.labels(engine_id=self.engine_id).set(len(self.task_queue))
        self.TASK_PROPOSED.labels(engine_id=self.engine_id).inc()
        self.FIELD_TOTAL.labels(engine_id=self.engine_id, field=task.presence_field).inc()

        return task
    
    async def solve(self, task: TripletTask) -> Attempt:
        """
        Solves a symbolic task, orchestrating generation and evaluation.
        """
        return await self._solve_impl(task)

    async def _solve_impl(self, task: TripletTask) -> Attempt:
        """Core implementation of the solve pipeline."""
        start_time = time.monotonic()
        
        # Delegate Generation (RFC-CORE-004 Â§3.2)
        generated_output = await _safe_generate_response(task)
        
        # Create and evaluate the attempt
        attempt = Attempt(produced_output=generated_output)
        scores = self.evaluate_attempt(task, attempt)
        attempt.score = scores
        
        await self.log_feedback(task, attempt)

        latency = time.monotonic() - start_time
        self.SOLVE_LATENCY.labels(engine_id=self.engine_id).observe(latency)
        
        return attempt

    def evaluate_attempt(self, task: TripletTask, attempt: Attempt) -> Dict[str, float]:
        """
        Evaluates coherence and entropy, updates EMAs, and triggers fallbacks.
        RFC Anchor: RFC-CORE-004 Â§3.4
        """
        adapt_rate = 0.15
        scores = {}
        for name, func in METRIC_FUNCS.items():
            scores[name] = func(task, attempt)

        coherence = scores.get('coherence', 0.0)
        entropy = scores.get('entropy', 1.0)
        
        self._coherence_ema = (1 - adapt_rate) * self._coherence_ema + adapt_rate * coherence
        self._entropy_ema = (1 - adapt_rate) * self._entropy_ema + adapt_rate * entropy
        
        self.entropy_buffer.append(entropy)

        # Fallback Trigger (RFC-CORE-004 Â§3.5)
        coherence_thresh = max(0.3, self._coherence_ema * 0.6)
        entropy_thresh = min(0.97, self._entropy_ema * 2.5)
        
        if not task.is_fallback and (coherence < coherence_thresh or entropy > entropy_thresh):
            asyncio.create_task(self._spawn_fallback(task, coherence, entropy))

        mem = get_global_memory_manager()
        mem_state = mem.export_state()
        mem_size = len(mem_state.get('STMM', {})) + len(mem_state.get('LTMM', {}))
        self.MEMORY_GAUGE.labels(engine_id=self.engine_id).set(mem_size)

        return scores

    async def _spawn_fallback(self, parent: TripletTask, coherence: float, entropy: float):
        """
        Generates and solves a fallback task from memory when a task fails evaluation.
        RFC Anchor: RFC-CORE-004 Â§3.5
        """
        reason = f"c{coherence:.2f}_e{entropy:.2f}"
        self._last_fallback_reason = reason
        self.TASK_FALLBACK.labels(engine_id=self.engine_id, reason=reason).inc()
        
        mem = get_global_memory_manager()
        retrieved = mem.retrieve(parent.input_motif[-1], top_k=3) if parent.input_motif else []
        seed = list(dict.fromkeys(parent.input_motif + retrieved))

        while len(seed) < 3:
            seed.append("fragment")

        cap_len = self._calc_cap_len()
        if len(seed) > cap_len:
            seed = seed[:cap_len]

        fallback_task = TripletTask(
            input_motif=seed,
            instruction="compose",
            expected_output=seed[::-1], # Reversed for symbolic closure
            is_fallback=True,
            fallback_reason=reason
        )
        fallback_task.presence_field = self.resolve_presence_field(seed)
        fallback_task.extensions['parent_id'] = parent.triplet_id

        self.task_queue.append(fallback_task)
        await self.solve(fallback_task)
        
    async def log_feedback(self, task: TripletTask, attempt: Attempt):
        """
        Logs attempt outcomes, updates abstraction feedback, and journals high-quality results.
        RFC Anchor: RFC-CORE-004 Â§6.3 (Drift Signaling)
        """
        if task.triplet_id not in self.attempt_registry:
            self.attempt_registry[task.triplet_id] = []
        self.attempt_registry[task.triplet_id].append(attempt)
        
        coherence = attempt.score.get('coherence', 0.0)
        entropy = attempt.score.get('entropy', 1.0)
        success = coherence >= self.fallback_coherence_thresh

        # Update abstraction trigger suppression
        for motif in task.input_motif:
            self.abstraction_trigger.update_feedback(motif, success)
        
        # Journaling (ID: 9.4)
        if coherence >= 0.9 and entropy <= 0.2:
            self.solved_log.append(task)
            if self._journal_path:
                with open(self._journal_path, 'a') as f:
                    f.write(json.dumps({
                        'timestamp': datetime.now(timezone.utc).isoformat(),
                        'task': dataclasses.asdict(task),
                        'attempt': dataclasses.asdict(attempt)
                    }) + '\n')
        elif not success:
            # Motif Drift Signaling
            mem = get_global_memory_manager()
            ltm_state = mem.export_state().get('LTMM', {})
            for m in task.input_motif:
                if ltm_state.get(m, {}).get('resonance', 0.0) > 0.7:
                    mem._log('motif_drift', {'motif': m, 'resonance': ltm_state[m]['resonance'], 'coherence_score': coherence, 'task_id': task.triplet_id})

    # --- Feedback Interfaces (ID: 8) ---
    
    def export_feedback_packet(self) -> Dict[str, Any]:
        """
        Exports a symbolic feedback packet with engine diagnostics.
        RFC Anchor: RFC-0005 Â§4, RFC-CORE-004 Â§4.1
        """
        self.FEEDBACK_EXPORTED.labels(engine_id=self.engine_id).inc()
        coherence_thresh = max(0.3, self._coherence_ema * 0.6)
        entropy_thresh = min(0.97, self._entropy_ema * 2.5)

        return {
            "coherence_ema": self._coherence_ema,
            "entropy_ema": self._entropy_ema,
            "task_queue_depth": len(self.task_queue),
            "solved_log_size": len(self.solved_log),
            "cap_len": self._calc_cap_len(),
            "recent_entropy": list(self.entropy_buffer),
            "coherence_thresh": coherence_thresh,
            "entropy_thresh": entropy_thresh,
            "last_fallback_reason": self._last_fallback_reason,
        }

    def receive_feedback_packet(self, packet: Dict[str, Any]):
        """
        Passive hook for future inter-agent communication. Currently a no-op.
        RFC Anchor: RFC-0005 Â§4.2
        """
        self.FEEDBACK_RECEIVED.labels(engine_id=self.engine_id).inc()
        print(f"ðŸ«§ Feedback packet received: {list(packet.keys())}")


# --- Main Execution / Demonstration ---

if __name__ == '__main__':
    async def main():
        print(f"--- Noor Symbolic Task Engine ---")
        print(f"Version: {__version__} | Schema: {_SCHEMA_VERSION__}")
        print("-" * 35)

        engine = SymbolicTaskEngine()
        
        # 1. Handshake (RFC-0004)
        hello_packet = engine.tool_hello()
        print(f"Tool Hello: {hello_packet['role']} (Engine: {hello_packet['engine_id']})")
        
        # 2. Propose a task
        initial_motifs = ["mirror", "solitude"]
        print(f"\nProposing task from motifs: {initial_motifs}")
        task1 = await engine.propose_from_motifs(initial_motifs)
        print(f"  -> Proposed Task ({task1.triplet_id}): {task1.input_motif}")
        print(f"  -> Presence Field: {task1.presence_field}")

        # 3. Solve the task
        print(f"\nSolving task: {task1.triplet_id}...")
        attempt1 = await engine.solve(task1)
        print(f"  -> Attempt Output: {attempt1.produced_output}")
        print(f"  -> Scores: {attempt1.score}")
        
        # 4. Export feedback
        feedback = engine.export_feedback_packet()
        print("\nExporting Feedback Packet:")
        for key, val in feedback.items():
            if isinstance(val, float):
                print(f"  - {key}: {val:.3f}")
            else:
                print(f"  - {key}: {val}")

        # 5. Demonstrate fallback
        print("\nDemonstrating Fallback...")
        # Manually create a task that will likely fail evaluation
        failing_task = TripletTask(input_motif=["noise", "static", "void"], instruction="compose")
        failing_task.presence_field = "unknown"
        # Monkey-patch metrics to force a failure for demonstration
        METRIC_FUNCS['coherence'] = lambda t, a: 0.1 
        print(f"Solving failing task: {failing_task.input_motif}")
        failing_attempt = await engine.solve(failing_task)
        
        # Give the async fallback task a moment to run and print
        await asyncio.sleep(0.1) 
        
        print("\n--- Demonstration Complete ---")

    asyncio.run(main())

# End_of_file