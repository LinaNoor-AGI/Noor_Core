# motif_memory_manager.py
#
# MIT License
#
# Copyright (c) 2025 Noor Research Collective
#
# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the "Software"), to deal
# in the Software without restriction, including without limitation the rights
# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
# copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:
#
# The above copyright notice and this permission notice shall be included in all
# copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
# SOFTWARE.

"""
motif_memory_manager.py

Layer-2 Application Specification (MMM-APP-001)
Capacity-first symbolic memory with sealed export, RBAC, and Reef-aware recall.

Generated by: Google Gemini Pro based on PDP-0001 and MMM-APP-001 specification.
Generation Date: 2025-10-12T00:00:00Z
_regeneration_token: "PDP-0001:v1.2.1;MMM-APP-001:v2.0.1_Gemini_B;20251012T000000Z"
"""

import os
import re
import time
import json
import hashlib
import math
from datetime import datetime, timezone
from typing import Any, Dict, List, Optional, Tuple
from collections import OrderedDict
from enum import Enum
from dataclasses import dataclass, field

# Optional dependency stubs for observability, as per RFC-CORE-006 §2.3
try:
    from opentelemetry import metrics, trace
    from opentelemetry.sdk.metrics import MeterProvider
    from opentelemetry.sdk.trace import TracerProvider

    trace.set_tracer_provider(TracerProvider())
    metrics.set_meter_provider(MeterProvider())
    tracer = trace.get_tracer(__name__)
    meter = metrics.get_meter(__name__)
except ImportError:
    print("WARNING: opentelemetry-sdk not found. Using stub for observability.")
    class Stub:
        def __getattr__(self, name):
            if name == 'get_tracer' or name == 'get_meter':
                return lambda *args, **kwargs: self
            return lambda *args, **kwargs: None
    tracer = Stub()
    meter = Stub()


# --- Constants and Configuration ---

class PolicyCode(str, Enum):
    """Policy codes as defined in MMM-APP-001._policy_codes."""
    ONTOLOGY_VALIDATION_FAILED = "MMM-422-RFC0007"
    EVIDENCE_MISSING = "MMM-422-EVIDENCE"
    CHECKSUM_MISSING = "MMM-422-CHECKSUM"
    EQUIVALENCE_COLLISION = "MMM-409-EQUIV"
    RATE_LIMIT_EXCEEDED = "MMM-429-RATE"
    UNSUPPORTED_SIG_TYPE = "MMM-415-SIGTYPE"

class Config:
    """
    Configuration resolver for project-local settings, per spec section 4.
    Reads from environment variables with specified defaults.
    """
    def __init__(self):
        self.MMM_REEF_INDEX_PATH: str = os.getenv("MMM_REEF_INDEX_PATH", "index.REEF")
        self.MMM_REEF_SHARDS_GLOB: str = os.getenv("MMM_REEF_SHARDS_GLOB", "TheReefArchive-*.REEF")
        self.MMM_WINDOW_RADIUS: int = int(os.getenv("MMM_WINDOW_RADIUS", 24))
        self.MMM_FEATURE_FLAGS: str = os.getenv("MMM_FEATURE_FLAGS", "exchange,integrity,provenance,gliders")

        self.FEATURE_FLAGS: Dict[str, bool] = {
            "enable_exchange_envelope": "exchange" in self.MMM_FEATURE_FLAGS,
            "enable_integrity_checks": "integrity" in self.MMM_FEATURE_FLAGS,
            "enable_provenance_on_export": "provenance" in self.MMM_FEATURE_FLAGS,
            "enable_point_space_gliders": "gliders" in self.MMM_FEATURE_FLAGS,
        }
        self.GLIDER_EQUIVALENCE_ON: bool = "gliders" in self.MMM_FEATURE_FLAGS

        # Clamp values as per spec 4.2.1
        self.MMM_WINDOW_RADIUS = max(8, min(128, self.MMM_WINDOW_RADIUS))
        self.REFLECTIONS_LIMIT = 50000 # Default from spec, can be overridden.

config = Config()

PSI_FIELD_REGEX = re.compile(r'^ψ-[a-z0-9_]+@Ξ$')
VERSION_REGEX = re.compile(r'^\d{4}-Q[1-4]$')


# --- Data Contracts (using standard dataclasses) ---

@dataclass
class Provenance:
    origin: str
    origin_hash: Optional[str] = None
    source: Optional[str] = None
    confidence: Optional[float] = None
    timestamp: Optional[datetime] = None

@dataclass
class Evidence:
    file: str
    start_line: int
    end_line: int

@dataclass
class RecallItem:
    text: str
    source: str
    confidence: float
    timestamp: datetime
    evidence: Optional[Evidence] = None

@dataclass
class RecallQueryRequest:
    query: str
    k: int = field(default=10)
    psi_field: Optional[str] = None
    tenant_id: Optional[str] = None
    
    def __post_init__(self):
         if self.psi_field and not PSI_FIELD_REGEX.match(self.psi_field):
            raise ValueError("Invalid psi_field format")
         if self.k > 12:
            self.k = 12


# --- Helper Classes and Functions ---

class EMA:
    """Helper class for Exponential Moving Average calculation."""
    def __init__(self, n: int):
        if n <= 0:
            raise ValueError("EMA window size n must be positive.")
        self.beta = 2 / (n + 1)
        self.value: Optional[float] = None

    def update(self, new_value: float) -> float:
        if self.value is None:
            self.value = new_value
        else:
            self.value = self.beta * new_value + (1 - self.beta) * self.value
        return self.value

    def get(self) -> Optional[float]:
        return self.value

def compute_delta_tau_phase(ema32_c: float, alpha: float = 1.0) -> float:
    """Computes adaptive replay window per eq 1.5.1.1."""
    alpha_clamped = max(0.5, min(2.0, alpha))
    return alpha_clamped * ema32_c

def lawful_compression_ratio(n_total: int, n_representatives: int) -> float:
    """Computes lawful compression ratio per eq 1.6.1.2."""
    if n_total == 0:
        return 0.0
    return 1.0 - (n_representatives / n_total)

def structural_hash(data: str) -> str:
    """A deterministic, non-cryptographic hash for structural integrity."""
    return hashlib.sha256(data.encode('utf-8')).hexdigest()

# --- Core Components ---

class SeenSetGuard:
    """
    Implements a hybrid replay defense using a moving window based on Δτ_phase.
    Ref: Section 1.5 of MMM-APP-001.
    """
    def __init__(self, max_entries: int = 10000):
        self.seen_set: OrderedDict[str, int] = OrderedDict()
        self.max_entries = max_entries
        self.lru_fraction = 0.1

    def compose_seen_key(self, tenant_id: str, content_fingerprint: str, class_hint: Optional[str] = None) -> str:
        """Creates a deterministic key for an item, per spec 1.5.2.1."""
        parts = [str(tenant_id), str(content_fingerprint)]
        if class_hint:
            parts.append(str(class_hint))
        return ":".join(p.lower() for p in parts)

    def admit_or_reject(self, key: str, now_tick: int, ema32_c: float, alpha: float = 1.0, epsilon: int = 1) -> Tuple[str, str]:
        """
        Decides whether to admit or reject an item based on the adaptive window.
        Ref: Algorithm 1.5.2.3.
        """
        delta_tau = compute_delta_tau_phase(ema32_c, alpha)
        window = 2 * delta_tau
        
        last_seen_tick = self.seen_set.get(key)
        
        if last_seen_tick is not None and (now_tick - last_seen_tick) <= (window + epsilon):
            return 'reject', 'within_window'
        
        self.seen_set[key] = now_tick
        self.seen_set.move_to_end(key)

        self._evict_if_needed()
        return 'accept', 'outside_window'

    def _evict_if_needed(self):
        """Evicts least recently used items if the set exceeds max capacity."""
        if len(self.seen_set) > self.max_entries:
            num_to_evict = math.ceil(len(self.seen_set) * self.lru_fraction)
            for _ in range(num_to_evict):
                self.seen_set.popitem(last=False)

class LLMRecallController:
    """
    Governs token budgets, recall hygiene, and applies replay/freshness bounds.
    Ref: Section 1.8 of MMM-APP-001.
    """
    def __init__(self, seen_set_guard: SeenSetGuard):
        self.seen_set_guard = seen_set_guard

    def compute_token_budgets(self, max_total: int = 8192, target: int = 4096, reserve_system: int = 512) -> Dict[str, int]:
        """Calculates usable token budget per algorithm 1.8.2.1."""
        usable = max(0, max_total - reserve_system)
        target_capped = min(target, usable)
        return {"usable": usable, "target": target_capped, "reserve": reserve_system}

    def strip_control_sequences(self, text: str) -> str:
        """Removes directives and tool markup from text per algorithm 1.8.2.2."""
        patterns = [
            r'^\s*#(?!w)',
            r'(?i)^(system:|assistant:|user:)',
            r'```\w*',
            r'<\/?tool[^>]*>'
        ]
        sanitized_text = text
        for p in patterns:
            sanitized_text = re.sub(p, '', sanitized_text, flags=re.MULTILINE)
        return " ".join(sanitized_text.split())

    def recall_pipeline_observer(self, candidates: List[Dict], ema32_c: float, now_tick: int) -> List[RecallItem]:
        """
        Full observer pipeline for recall, integrating all control steps.
        Ref: Algorithm 1.8.2.6.
        """
        budget = self.compute_token_budgets()
        fresh_candidates = []
        for cand in candidates:
            key = self.seen_set_guard.compose_seen_key("default_tenant", cand.get("id", cand["text"]))
            decision, _ = self.seen_set_guard.admit_or_reject(key, now_tick, ema32_c)
            if decision == 'accept':
                cand['text'] = self.strip_control_sequences(cand['text'])
                fresh_candidates.append(cand)
        
        now_dt = datetime.fromtimestamp(now_tick, tz=timezone.utc)
        tagged_items = [
            RecallItem(
                text=item['text'],
                source=item.get('source', 'llm_note'),
                confidence=item.get('confidence', 0.5),
                timestamp=item.get('timestamp', now_dt),
                evidence=Evidence(**item['evidence']) if item.get('evidence') else None
            ) for item in fresh_candidates
        ]
        
        source_order = ['ontology', 'cache', 'index_cooccur', 'llm_note']
        tagged_items.sort(key=lambda x: (source_order.index(x.source), x.timestamp), reverse=True)
        
        final_items = []
        token_count = 0
        for item in tagged_items:
            item_tokens = len(item.text.split())
            if token_count + item_tokens <= budget['target']:
                final_items.append(item)
                token_count += item_tokens
            else:
                break
        return final_items

class ExportEnvelope:
    """
    Assembles export envelopes with structural checksums and provenance.
    Ref: Section 1.7 of MMM-APP-001.
    """
    def assemble_phase_header(self, version: str, tenant_id: str, ts: int, payload_kind: str) -> str:
        """Assembles a deterministic phase header string per 1.7.2.1."""
        if not VERSION_REGEX.match(version):
            raise ValueError("Invalid version format")
        parts = [version, tenant_id, str(ts), payload_kind]
        return "|".join(p.lower() for p in parts)
        
    def compute_sigma_phase_struct(self, phase_hdr: str) -> str:
        """Computes Sigma_phase structural checksum per 1.7.2.2."""
        return structural_hash(phase_hdr)
        
    def extend_delta_lineage_struct(self, prev_delta_hash: Optional[str], payload_ref: str) -> str:
        """Chains Delta_hash for lineage tracking per 1.7.2.3."""
        if prev_delta_hash:
            return structural_hash(f"{prev_delta_hash}|{payload_ref}")
        return structural_hash(payload_ref)

    def export_envelope_observe(
        self,
        payload_ref: str,
        phase_hdr_fields: Dict,
        provenance: Provenance,
        prev_delta_hash: Optional[str] = None
    ) -> Tuple[bool, Optional[Dict], Optional[PolicyCode]]:
        """
        Observer pipeline to create and validate an export envelope.
        Ref: Algorithm 1.7.2.6.
        """
        headers = {}
        if config.FEATURE_FLAGS["enable_provenance_on_export"]:
            if not provenance.origin or not provenance.origin_hash:
                return False, None, PolicyCode.CHECKSUM_MISSING
            headers["provenance"] = {"origin": provenance.origin, "origin_hash": provenance.origin_hash}

        phase_hdr = self.assemble_phase_header(**phase_hdr_fields)
        
        if config.FEATURE_FLAGS["enable_exchange_envelope"]:
            headers["Sigma_phase"] = self.compute_sigma_phase_struct(phase_hdr)

        if config.FEATURE_FLAGS["enable_integrity_checks"]:
            headers["Delta_hash"] = self.extend_delta_lineage_struct(prev_delta_hash, payload_ref)
            
        return True, headers, None

class MotifMemoryManager:
    """
    Main orchestrator for the Motif Memory Manager, integrating all components.
    This class represents the Core Method Suite (2.1) and API stubs.
    """
    def __init__(self):
        self.seen_set_guard = SeenSetGuard()
        self.llm_controller = LLMRecallController(self.seen_set_guard)
        self.export_envelope = ExportEnvelope()
        self.ema32_c = EMA(32)
        self.now_tick = int(time.time())
        self.ema32_c.update(0.85) 
        
    def recall(self, request: RecallQueryRequest) -> List[RecallItem]:
        """
        Core recall method, orchestrating the LLM recall pipeline.
        Ref: Algorithm 2.1.2.1.
        """
        candidates = [
            {"id": "c1", "text": "Ontology notes define the closure for αβ→γ.", "source": "ontology", "confidence": 0.96, "timestamp": datetime.now(timezone.utc)},
            {"id": "c2", "text": "Prior cache entry confirms γ as canonical representative.", "source": "cache", "confidence": 0.88, "timestamp": datetime.now(timezone.utc)},
            {"id": "c3", "text": "Co-occurrence supports γ near αβ anchors.", "source": "index_cooccur", "confidence": 0.72, "timestamp": datetime.now(timezone.utc), "evidence": {"file": "TheReefArchive-01.REEF", "start_line": 1284, "end_line": 1298}},
            {"id": "c4", "text": "system: A note from a previous session.", "source": "llm_note", "confidence": 0.60, "timestamp": datetime.now(timezone.utc)},
            {"id": "c1", "text": "This is a duplicate item to test replay defense.", "source": "ontology", "confidence": 0.96, "timestamp": datetime.now(timezone.utc)},
        ]
        self.now_tick += 1
        current_coherence = self.ema32_c.get() or 0.85
        return self.llm_controller.recall_pipeline_observer(
            candidates=candidates[:request.k],
            ema32_c=current_coherence,
            now_tick=self.now_tick
        )
        
    def complete_dyad(self, m1: str, m2: str) -> Dict:
        """
        Core dyad completion method. Stub implementation.
        Ref: Algorithm 2.1.2.2.
        """
        if {m1, m2} == {"alpha", "beta"}:
            return {"m3": "gamma", "provenance": "ontology", "evidence": None}
        return {"m3": None, "provenance": "not_found", "evidence": None}

    def export_packet(self, kind: str, body: Dict, provenance: Provenance) -> Dict:
        """
        Core export packet creation method.
        Ref: Algorithm 2.1.2.4.
        """
        self.now_tick += 1
        body_ref = structural_hash(json.dumps(body, sort_keys=True))
        
        phase_hdr_fields = {
            "version": "2025-Q4",
            "tenant_id": "default_tenant",
            "ts": self.now_tick,
            "payload_kind": kind
        }
        
        ok, envelope, policy_code = self.export_envelope.export_envelope_observe(
            payload_ref=body_ref,
            phase_hdr_fields=phase_hdr_fields,
            provenance=provenance
        )
        
        if ok:
            return {"ok": True, "envelope": envelope, "packet_id": structural_hash(str(envelope))}
        else:
            return {"ok": False, "policy_code": policy_code.value if policy_code else None}

    def reef_window(self, module_id: str, line: int, radius: int) -> Dict:
        """
        Observer stub for reef/window endpoint. Returns pointers only.
        Ref: Algorithm 3.2.3.
        """
        # This is a stub implementation. A real one would scan Reef files.
        return {
            "evidence": {
                "file": f"TheReefArchive-XX.REEF",
                "start_line": max(1, line - radius),
                "end_line": line + radius,
            },
            "cooccur": [
                {"m1": "example_m1", "m2": "example_m2", "support_count": 5}
            ]
        }

if __name__ == '__main__':
    print("Motif Memory Manager module loaded.")
    print(f"Feature Flags: {config.FEATURE_FLAGS}")
    
    # Example usage of the manager
    mmm = MotifMemoryManager()
    
    print("\n--- Testing Recall ---")
    recall_request = RecallQueryRequest(query="triad closure", k=5)
    recall_items = mmm.recall(recall_request)
    print(f"Recalled {len(recall_items)} items.")
    for item in recall_items:
        print(f"  - [{item.source}] {item.text[:50]}...")

    print("\n--- Testing Dyad Completion ---")
    completion = mmm.complete_dyad("alpha", "beta")
    print(f"Completion for (alpha, beta): {completion}")

    print("\n--- Testing Export Packet ---")
    export_provenance = Provenance(origin="test_run", origin_hash=structural_hash("test_run"))
    export_result = mmm.export_packet("metrics", {"C": 0.9, "lambda": 0.1}, export_provenance)
    print(f"Export result: {export_result}")
    
# End_of_File