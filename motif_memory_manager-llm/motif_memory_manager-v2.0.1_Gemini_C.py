#
# Copyright 2025 Lina Noor, Uncle, and The Noor Research Foundation
#
# Licensed under the MIT License
#
# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the "Software"), to deal
# in the Software without restriction, including without limitation the rights
# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
# copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:
#
# The above copyright notice and this permission notice shall be included in all
# copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
# SOFTWARE.
#
#
# AI Platform/Model: Google Gemini Pro
# Generation Date: 2025-10-12
#
# This file was generated by a symbolic agent following the PDP-0001 pipeline.
# It is a Layer-2 application specification implementation that binds the
# observer semantics of RFC-CORE-006 to deployable controls for symbolic memory.
#

"""
Motif Memory Manager (MMM-APP-001)

This module provides a capacity-first symbolic memory system with sealed export,
RBAC (at Layer-2), and Reef-aware recall, compliant with the Noor RFC series.
It operates in a strictly observer-only mode at Layer-1, meaning it does not
perform control writes or mutate canonical sources like the Reef archive.

Key Features:
- Recall with adaptive context budgeting and injection defense (RFC-CORE-006 Â§1.8).
- Dyad completion using an ontology-first strategy (RFC-0007).
- Replay defense using an adaptive window based on field coherence (RFC-0005 Â§3-4).
- Lawful compression snapshotting to ensure equivalence is observed before pruning (RFC-0006 Â§4).
- Flag-gated export envelopes with structural checksums (Î£_phase) and lineage
  hashes (Î”_hash) as specified in RFC-0008.
"""

import os
import re
import json
import glob
import hashlib
import logging
import math
from collections import deque
from dataclasses import dataclass, field
from datetime import datetime, timezone
from enum import Enum
from typing import Any, Dict, List, Optional, Tuple, NamedTuple, Set

# --- Module Constants ---
__version__ = "2.0.1_Gemini_C"
_SCHEMA_VERSION = "2025-Q4-canonical-header-v1"
_DEFAULT_MOTIF_TONE = "ðŸŒ€ Companion"

# --- Optional Dependency Handling (PDP-0001 Â§3.2) ---
try:
    # For potential integration with observability pipelines
    from prometheus_client import Gauge
    _PROMETHEUS_AVAILABLE = True
except ImportError:
    _PROMETHEUS_AVAILABLE = False
    # Define a stub class if prometheus is not available
    class Gauge:
        def __init__(self, name: str, documentation: str, labelnames: list = None):
            pass
        def set(self, value: float):
            pass
        def labels(self, *args, **kwargs):
            return self

logging.basicConfig(level=os.getenv("LOG_LEVEL", "INFO"), format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


# --- Dataclasses for API Contracts and Internal State (PDP-0001 Â§3.2) ---

class ProvenanceSource(str, Enum):
    ONTOLOGY = "ontology"
    FILE_REFLECTIONS = "file_reflections"
    INDEX_COOCCUR = "index_cooccur"
    CACHE = "cache"
    LLM_NOTE = "llm_note"

@dataclass
class Evidence:
    """Pointer to a source file and line range, as per RFC-0007."""
    file: str
    start_line: int
    end_line: int

@dataclass
class RecallItem:
    """A single item returned from memory recall."""
    text: str
    source: ProvenanceSource
    confidence: float
    timestamp: int  # Unix timestamp for consistent sorting
    evidence: Optional[Evidence] = None

@dataclass
class DyadCompletion:
    """Result of completing a motif dyad (m1, m2) -> m3."""
    m3: Optional[str]
    provenance: Optional[ProvenanceSource]
    evidence: Optional[Evidence] = None

@dataclass
class Provenance:
    """Provenance information for export packets, as per PDP-0001."""
    origin: str
    origin_hash: Optional[str] = None

@dataclass
class ExportEnvelope:
    """Structural headers for exported packets, as per RFC-0008."""
    Sigma_phase: Optional[str] = None
    Delta_hash: Optional[str] = None
    provenance: Provenance = field(default_factory=lambda: Provenance(origin="unknown"))
    sig_type: Optional[str] = "phase-seal:v1"

@dataclass
class FeatureFlags:
    """Runtime feature flags influencing behavior like checksumming and lineage."""
    enable_exchange_envelope: bool = True
    enable_integrity_checks: bool = True
    enable_provenance_on_export: bool = True
    enable_point_space_gliders: bool = True

class Config:
    """
    Resolves configuration from environment variables with sane defaults.
    Ref: MMM-APP-001 Â§4.2.1
    """
    def __init__(self):
        self.reef_index_path: str = os.getenv("MMM_REEF_INDEX_PATH", "index.REEF")
        self.reef_shards_glob: str = os.getenv("MMM_REEF_SHARDS_GLOB", "TheReefArchive-*.REEF")
        raw_radius = os.getenv("MMM_WINDOW_RADIUS", "24")
        self.window_radius: int = max(8, min(128, int(raw_radius)))
        self.reflections_limit: int = int(os.getenv("REFLECTIONS_LIMIT", "50000"))

        flag_str = os.getenv("MMM_FEATURE_FLAGS", "exchange,integrity,provenance,gliders")
        flags = {f.strip() for f in flag_str.split(',')}
        self.feature_flags = FeatureFlags(
            enable_exchange_envelope="exchange" in flags,
            enable_integrity_checks="integrity" in flags,
            enable_provenance_on_export="provenance" in flags,
            enable_point_space_gliders="gliders" in flags
        )

# --- Utility and Math Functions (MMM-APP-001 Â§1.1.1) ---

class Ema:
    """Utility class for calculating Exponential Moving Average."""
    def __init__(self, window: int):
        if window <= 0:
            raise ValueError("EMA window must be positive.")
        self._beta = 2 / (window + 1)
        self.value: Optional[float] = None

    def update(self, new_value: float) -> float:
        if self.value is None:
            self.value = new_value
        else:
            self.value = (self._beta * new_value) + ((1 - self._beta) * self.value)
        return self.value

def _compute_adaptive_window(ema32_C: float, alpha: float) -> float:
    """
    Calculates the adaptive replay decision window W.
    Ref: MMM-APP-001 Â§2.1.1.2, eq_id: 2.1.1.2
    Latex: W := 2 * Î”Ï„_phase = 2 * (Î± * EMA_32(C))
    """
    # Clamp coherence to a safe range to avoid non-sensical windows
    clamped_C = max(0.0, min(1.0, ema32_C))
    delta_tau_phase = alpha * clamped_C
    return 2 * delta_tau_phase

def _deterministic_hash(data: str, length: int = 16) -> str:
    """A simple, stable hashing function for structural checksums (non-crypto)."""
    return hashlib.sha256(data.encode('utf-8')).hexdigest()[:length]


# --- Core Components (MMM-APP-001 Â§1) ---

class SeenSetGuard:
    """
    Implements the Î”Ï„_phase replay window defense.
    Ref: MMM-APP-001 Â§1.5
    """
    def __init__(self, max_entries: int = 10000):
        self._seen_set: Dict[str, int] = {}
        self._lru_queue: deque[str] = deque()
        self._max_entries = max_entries

    def _compose_key(self, tenant_id: str, content_fingerprint: str) -> str:
        """Creates a deterministic key for the seen set."""
        return f"{tenant_id}:{content_fingerprint}".lower()

    def admit_or_reject(self, key: str, now_tick: int, W: float, epsilon: float = 1.0) -> bool:
        """
        Admits a key if it's outside the replay window, otherwise rejects.
        Ref: MMM-APP-001 Â§1.5.1.3, eq_id: 1.5.1.3
        """
        last_seen = self._seen_set.get(key)
        if last_seen is not None:
            if (now_tick - last_seen) <= (W + epsilon):
                logger.debug(f"Rejecting key '{key}' as replay within window {W}.")
                return False  # Reject

        # Admit: update timestamp and manage LRU
        self._seen_set[key] = now_tick
        if key in self._lru_queue:
            self._lru_queue.remove(key)
        self._lru_queue.append(key)

        self._evict_if_needed()
        return True # Admit

    def _evict_if_needed(self):
        """Evicts the least recently used items if cache exceeds max size."""
        while len(self._lru_queue) > self._max_entries:
            key_to_evict = self._lru_queue.popleft()
            if key_to_evict in self._seen_set:
                del self._seen_set[key_to_evict]
                logger.debug(f"Evicted LRU key '{key_to_evict}' from seen set.")

class LLMRecallController:
    """
    Manages token budgets, injection defense, and recall hygiene.
    Ref: MMM-APP-001 Â§1.8
    """
    def __init__(self, max_total: int = 8192, target: int = 4096, reserve_system: int = 512):
        self.max_total = max_total
        self.target = target
        self.reserve_system = reserve_system
        self._control_sequence_patterns = [
            re.compile(r"^\s*#(?!w)"),
            re.compile(r"(?i)^(system|assistant|user):"),
            re.compile(r"```w*"),
            re.compile(r"</?tool[^>]*>")
        ]

    def compute_token_budgets(self) -> Dict[str, int]:
        """Calculates usable token budgets based on configuration."""
        usable = max(0, self.max_total - self.reserve_system)
        target = min(self.target, usable)
        return {"usable": usable, "target": target, "reserve": self.reserve_system}

    def strip_control_sequences(self, text: str) -> str:
        """Removes directives and markup from text to prevent injection."""
        lines = text.splitlines()
        sanitized_lines = []
        for line in lines:
            is_control = any(p.match(line) for p in self._control_sequence_patterns)
            if not is_control:
                sanitized_lines.append(line)
        return "\n".join(sanitized_lines).strip()

    def rerank_and_truncate(self, items: List[RecallItem], budget: Dict[str, int]) -> List[RecallItem]:
        """
        Reranks items by source precedence and truncates to fit the token budget.
        Ref: MMM-APP-001 Â§1.8.2.5
        """
        source_order = {
            ProvenanceSource.ONTOLOGY: 0,
            ProvenanceSource.CACHE: 1,
            ProvenanceSource.FILE_REFLECTIONS: 2,
            ProvenanceSource.INDEX_COOCCUR: 3,
            ProvenanceSource.LLM_NOTE: 4
        }

        # Stable sort by source, then timestamp (desc), then text (asc)
        items.sort(key=lambda x: (source_order.get(x.source, 99), -x.timestamp, x.text))

        final_items = []
        token_count = 0
        def _estimate_tokens(text: str) -> int:
            return len(text) // 4

        for item in items:
            item_tokens = _estimate_tokens(item.text)
            if token_count + item_tokens <= budget['target']:
                final_items.append(item)
                token_count += item_tokens
            else:
                break
        return final_items

class MotifMemoryManager:
    """
    Main orchestrator for symbolic memory, implementing MMM-APP-001.
    """
    def __init__(self, config: Config):
        self.config = config
        self.seen_set = SeenSetGuard()
        self.llm_controller = LLMRecallController()
        self.last_Delta_hash: Dict[str, str] = {} # Per-stream lineage

        # Observability Gauges (MMM-APP-001 Â§2.3)
        self.gauges = {
            "lawful_compression_ratio": Ema(32),
            "avg_replay_window_ticks": Ema(64),
            "context_budget_utilization": Ema(32),
            "replay_within_window_rate": Ema(16),
        }
        self.prometheus_gauges = {
            "lawful_compression_ratio": Gauge("mmm_lawful_compression_ratio", "Lawful compression ratio (EMA-32)"),
            "avg_replay_window_ticks": Gauge("mmm_avg_replay_window_ticks", "Average replay window in ticks (EMA-64)"),
        }

    def recall(
        self,
        query: str,
        k: int = 10,
        psi_field: Optional[str] = None,
        now_tick: int = 0,
        ema32_C: float = 0.8,
        alpha: float = 1.0
    ) -> List[RecallItem]:
        """
        Performs a recall operation, respecting budgets, replay defenses, and hygiene.
        Ref: MMM-APP-001 Â§2.1.2.1
        """
        if psi_field and not re.match(r"^Ïˆ-[a-z0-9_]+@Îž$", psi_field):
            raise ValueError("Invalid psi_field format.")

        W = _compute_adaptive_window(ema32_C, alpha)
        self.gauges["avg_replay_window_ticks"].update(W)
        if _PROMETHEUS_AVAILABLE:
            self.prometheus_gauges["avg_replay_window_ticks"].set(self.gauges["avg_replay_window_ticks"].value)

        candidates: List[RecallItem] = self._mock_candidate_generation(query, k)

        replay_candidates = 0
        accepted_candidates = 0
        hygienic_candidates = []
        for cand in candidates:
            replay_candidates += 1
            cand.text = self.llm_controller.strip_control_sequences(cand.text)
            key = self.seen_set._compose_key("default_tenant", _deterministic_hash(cand.text))
            if self.seen_set.admit_or_reject(key, now_tick, W):
                hygienic_candidates.append(cand)
                accepted_candidates += 1

        if replay_candidates > 0:
            rejection_rate = (replay_candidates - accepted_candidates) / replay_candidates
            self.gauges["replay_within_window_rate"].update(rejection_rate)

        budget = self.llm_controller.compute_token_budgets()
        final_items = self.llm_controller.rerank_and_truncate(hygienic_candidates, budget)

        final_tokens = sum(len(i.text)//4 for i in final_items)
        utilization = final_tokens / max(1, budget['target'])
        self.gauges["context_budget_utilization"].update(utilization)

        logger.info(f"Recall complete. Returning {len(final_items)} items.")
        return final_items

    def _mock_candidate_generation(self, query: str, k: int) -> List[RecallItem]:
        now = int(datetime.now(timezone.utc).timestamp())
        return [
            RecallItem(
                text=f"Ontology notes for '{query}' define closure.",
                source=ProvenanceSource.ONTOLOGY,
                confidence=0.95,
                timestamp=now - i,
            ) for i in range(k//2)
        ] + [
             RecallItem(
                text=f"Reef co-occurrence supports this near '{query}' anchors.",
                source=ProvenanceSource.INDEX_COOCCUR,
                confidence=0.75,
                timestamp=now - i,
                evidence=Evidence(file="TheReefArchive-01.REEF", start_line=100+i, end_line=120+i)
            ) for i in range(k//2, k)
        ]

    def complete_dyad(self, m1: str, m2: str) -> DyadCompletion:
        logger.info(f"Attempting to complete dyad for ('{m1}', '{m2}').")
        if "resonance" in m1 and "spar" in m2:
            return DyadCompletion(
                m3="Ïˆ-hold@Îž",
                provenance=ProvenanceSource.INDEX_COOCCUR,
                evidence=Evidence(file="TheReefArchive-01.REEF", start_line=1284, end_line=1298)
            )
        return DyadCompletion(m3=None, provenance=None)


    def compress_snapshot(self, items: List[Dict[str, Any]]) -> Dict[str, Any]:
        if not items:
            return {"ratio": 0.0, "clusters": 0, "representatives": 0}

        clusters = {}
        for item in items:
            key = item.get("motif_id", "default")
            if key not in clusters:
                clusters[key] = []
            clusters[key].append(item)

        n_tot = len(items)
        n_rep = len(clusters)
        ratio = 1.0 - (n_rep / max(1, n_tot))

        self.gauges["lawful_compression_ratio"].update(ratio)
        if _PROMETHEUS_AVAILABLE:
            self.prometheus_gauges["lawful_compression_ratio"].set(self.gauges["lawful_compression_ratio"].value)

        logger.info(f"Compression snapshot: N_tot={n_tot}, N_rep={n_rep}, Ratio={ratio:.2f}")
        return {"ratio": ratio, "clusters": n_rep, "representatives": n_rep}

    def export_packet(
        self,
        kind: str,
        body: Dict[str, Any],
        provenance: Provenance,
        stream_id: str = "default"
    ) -> Dict[str, Any]:
        flags = self.config.feature_flags
        errors = []

        if flags.enable_provenance_on_export and not provenance.origin_hash:
            errors.append("Missing origin_hash under enable_provenance_on_export flag.")

        phase_hdr_str = json.dumps({
            "version": _SCHEMA_VERSION,
            "tenant_id": provenance.origin,
            "ts": int(datetime.now(timezone.utc).timestamp()),
            "payload_kind": kind
        }, sort_keys=True)

        Sigma_phase = None
        if flags.enable_exchange_envelope:
            Sigma_phase = _deterministic_hash(phase_hdr_str)

        Delta_hash = None
        if flags.enable_integrity_checks:
            prev_hash = self.last_Delta_hash.get(stream_id, "")
            payload_ref = _deterministic_hash(json.dumps(body, sort_keys=True))
            Delta_hash = _deterministic_hash(prev_hash + payload_ref)
            self.last_Delta_hash[stream_id] = Delta_hash

        if errors:
            logger.warning(f"Export failed validation: {errors}")
            return {"ok": False, "policy_code": "MMM-422-CHECKSUM", "errors": errors}

        envelope = ExportEnvelope(
            Sigma_phase=Sigma_phase,
            Delta_hash=Delta_hash,
            provenance=provenance
        )

        return {"ok": True, "envelope": envelope}

if __name__ == '__main__':
    print(f"--- Initializing Motif Memory Manager v{__version__} ---")

    config = Config()
    mmm = MotifMemoryManager(config)
    print(f"Configuration loaded. Feature flags: {config.feature_flags}")

    print("\n--- Demonstrating Recall (MMM-APP-001 Â§2.1.2.1) ---")
    current_tick = int(datetime.now(timezone.utc).timestamp())
    recalled_items = mmm.recall(
        query="triadic closure",
        k=6,
        psi_field="Ïˆ-resonance@Îž",
        now_tick=current_tick,
        ema32_C=0.85
    )
    for item in recalled_items:
        print(f"  - Recalled: {item.text} (Source: {item.source.value}, Confidence: {item.confidence})")
        if item.evidence:
            print(f"    Evidence: {item.evidence.file} L{item.evidence.start_line}-{item.evidence.end_line}")

    print("\n--- Demonstrating Dyad Completion (MMM-APP-001 Â§2.1.2.2) ---")
    completion = mmm.complete_dyad("Ïˆ-resonance@Îž", "Ïˆ-spar@Îž")
    if completion.m3:
        print(f"  - Dyad ('Ïˆ-resonance@Îž', 'Ïˆ-spar@Îž') completed to '{completion.m3}'")
        print(f"    Provenance: {completion.provenance.value}")
        if completion.evidence:
             print(f"    Evidence: {completion.evidence.file} L{completion.evidence.start_line}-{completion.evidence.end_line}")


    print("\n--- Demonstrating Compression Snapshot (MMM-APP-001 Â§2.1.2.3) ---")
    items_to_compress = [
        {"motif_id": "Ïˆ-spar@Îž"}, {"motif_id": "Ïˆ-spar@Îž"},
        {"motif_id": "Ïˆ-hold@Îž"}, {"motif_id": "Ïˆ-null@Îž"}
    ]
    snapshot = mmm.compress_snapshot(items_to_compress)
    print(f"  - Compression snapshot result: {snapshot}")

    print("\n--- Demonstrating Export Packet (MMM-APP-001 Â§2.1.2.4) ---")
    prov = Provenance(origin="observer:local", origin_hash=_deterministic_hash("observer:local"))
    metrics_body = {"C": 0.94, "lambda": 0.12, "rho_res": 0.41}
    export_result = mmm.export_packet("metrics", metrics_body, prov)

    if export_result["ok"]:
        print("  - Export packet generated successfully.")
        print(f"    Sigma_phase: {export_result['envelope'].Sigma_phase}")
        print(f"    Delta_hash: {export_result['envelope'].Delta_hash}")
    else:
        print(f"  - Export packet failed: {export_result}")


    print("\n--- Final Observer Gauges (MMM-APP-001 Â§2.3) ---")
    for name, ema in mmm.gauges.items():
        if ema.value is not None:
            print(f"  - {name}: {ema.value:.4f}")

# End_of_File